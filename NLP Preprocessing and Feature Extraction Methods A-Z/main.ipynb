{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import the modules and load the raw data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 4.53 µs\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 ../.kaggle/kaggle.json'\r\n",
      "nlp-getting-started.zip: Skipping, found more recently modified local copy (use --force to force download)\r\n",
      "Archive:  nlp-getting-started.zip\r\n",
      "Python version: 3.8.5 (default, May 27 2021, 13:30:53) \n",
      "[GCC 9.3.0]\n",
      "Version info.: sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0)\n",
      "pandas version: 1.2.3\n",
      "numpy version: 1.19.5\n",
      "skearn version: 0.24.1\n",
      "./nlp-getting-started.zip\n",
      "./test.csv\n",
      "./helpers.py\n",
      "./main.py\n",
      "./sample_submission.csv\n",
      "./main.ipynb\n",
      "./train.csv\n",
      "./__pycache__/helpers.cpython-38.pyc\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import textblob\n",
    "import nltk\n",
    "\n",
    "from helpers import *\n",
    "\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = \"../.kaggle/\"\n",
    "!kaggle competitions download -c nlp-getting-started\n",
    "!unzip -n 'nlp-getting-started'\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Version info.:\", sys.version_info)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"skearn version:\", sklearn.__version__)\n",
    "\n",
    "for dirname, _, filenames in os.walk('.'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the raw data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                    keyword    location  \\\nid                                        \n2075               casualty  Toledo, OH   \n9059   structural%20failure         USA   \n5178             fatalities         NaN   \n10702                 wreck         NaN   \n3074                 deaths         NaN   \n\n                                                    text  target  \nid                                                                \n2075   Casualty Team: Ice Cream Recall Sends Chill Th...       0  \n9059   Virgin galactic crash: early unlocking of brak...       1  \n5178   Injuries Illnesses and Fatalities Latest Numbe...       1  \n10702  the sunset boys wreck my bed   original 1979 u...       1  \n3074   @Eazzy_P we will never know what would have ha...       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2075</th>\n      <td>casualty</td>\n      <td>Toledo, OH</td>\n      <td>Casualty Team: Ice Cream Recall Sends Chill Th...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9059</th>\n      <td>structural%20failure</td>\n      <td>USA</td>\n      <td>Virgin galactic crash: early unlocking of brak...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5178</th>\n      <td>fatalities</td>\n      <td>NaN</td>\n      <td>Injuries Illnesses and Fatalities Latest Numbe...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10702</th>\n      <td>wreck</td>\n      <td>NaN</td>\n      <td>the sunset boys wreck my bed   original 1979 u...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3074</th>\n      <td>deaths</td>\n      <td>NaN</td>\n      <td>@Eazzy_P we will never know what would have ha...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", index_col=\"id\")\n",
    "train_df.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the text to lower case"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "   keyword location                                    text  target  \\\nid                                                                    \n4      NaN      NaN  Forest fire near La Ronge Sask. Canada       1   \n\n                                text_clean  \nid                                          \n4   forest fire near la ronge sask. canada  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>text_clean</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n      <td>forest fire near la ronge sask. canada</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text_clean\"] = train_df[\"text\"].apply(lambda x: x.lower())\n",
    "train_df[1:2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert contractions to non-contraction form (eg. I'd -> I had)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "     keyword location                                               text  \\\nid                                                                         \n96  accident   CLVLND  'I can't have kids cuz I got in a bicycle acci...   \n\n    target                                         text_clean  \nid                                                             \n96       0  'i can not have kids cuz i got in a bicycle ac...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>text_clean</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>96</th>\n      <td>accident</td>\n      <td>CLVLND</td>\n      <td>'I can't have kids cuz I got in a bicycle acci...</td>\n      <td>0</td>\n      <td>'i can not have kids cuz i got in a bicycle ac...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: contractions.fix(x))\n",
    "train_df[67:68]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove any URLs from the text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "       keyword location                                               text  \\\nid                                                                           \n277  ambulance    L. A.  http://t.co/pWwpUm6RBj Twelve feared killed in...   \n\n     target                                         text_clean  \nid                                                              \n277       1   twelve feared killed in pakistani air ambulan...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>text_clean</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>277</th>\n      <td>ambulance</td>\n      <td>L. A.</td>\n      <td>http://t.co/pWwpUm6RBj Twelve feared killed in...</td>\n      <td>1</td>\n      <td>twelve feared killed in pakistani air ambulan...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_URL(x))\n",
    "train_df[197:198]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove HTML tags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "   keyword                     location  \\\nid                                        \n89  ablaze  Twitter Lockout in progress   \n\n                                                 text  target  \\\nid                                                              \n89  Rene Ablaze &amp; Jacinta - Secret 2k13 (Falle...       0   \n\n                                           text_clean  \nid                                                     \n89  rene ablaze  jacinta - secret 2k13 (fallen ski...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>text_clean</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>89</th>\n      <td>ablaze</td>\n      <td>Twitter Lockout in progress</td>\n      <td>Rene Ablaze &amp;amp; Jacinta - Secret 2k13 (Falle...</td>\n      <td>0</td>\n      <td>rene ablaze  jacinta - secret 2k13 (fallen ski...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_html(x))\n",
    "train_df[62:63]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove non-ASCII"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "   keyword location                                               text  \\\nid                                                                       \n56  ablaze      NaN  Barbados #Bridgetown JAMAICA ÛÒ Two cars set ...   \n\n    target                                         text_clean  \nid                                                             \n56       1  barbados #bridgetown jamaica  two cars set abl...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>text_clean</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>56</th>\n      <td>ablaze</td>\n      <td>NaN</td>\n      <td>Barbados #Bridgetown JAMAICA ÛÒ Two cars set ...</td>\n      <td>1</td>\n      <td>barbados #bridgetown jamaica  two cars set abl...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_non_ascii(x))\n",
    "train_df[38:39]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove special characters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "                 keyword                   location  \\\nid                                                    \n205  airplane%20accident  Hyderabad Telangana INDIA   \n\n                                                  text  target  \\\nid                                                               \n205  Horrible Accident  Man Died In Wings of Airpla...       1   \n\n                                            text_clean  \nid                                                      \n205  horrible accident  man died in wings of airpla...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>text_clean</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>205</th>\n      <td>airplane%20accident</td>\n      <td>Hyderabad Telangana INDIA</td>\n      <td>Horrible Accident  Man Died In Wings of Airpla...</td>\n      <td>1</td>\n      <td>horrible accident  man died in wings of airpla...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_special_characters(x))\n",
    "train_df[143:144]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove punctuation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "   keyword location                                               text  \\\nid                                                                       \n8      NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n\n    target                                         text_clean  \nid                                                             \n8        1  rockyfire update  california hwy 20 closed in ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>text_clean</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n      <td>1</td>\n      <td>rockyfire update  california hwy 20 closed in ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_punct(x))\n",
    "train_df[5:6]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean the rest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 0 ns, total: 1.05 s\n",
      "Wall time: 1.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "      keyword      location  \\\nid                            \n2651  crashed  Buenos Aires   \n\n                                                   text  target  \\\nid                                                                \n2651  MH370: Intact part lifts odds plane glided not...       1   \n\n                                             text_clean  \nid                                                       \n2651  malaysia airlines flight 370 intact part lifts...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>text_clean</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2651</th>\n      <td>crashed</td>\n      <td>Buenos Aires</td>\n      <td>MH370: Intact part lifts odds plane glided not...</td>\n      <td>1</td>\n      <td>malaysia airlines flight 370 intact part lifts...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: other_clean(x))\n",
    "train_df[1844:1845]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove spelling errors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# %%time\n",
    "# train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: textblob.TextBlob(x).correct())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Break words into a list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001B[93mpunkt\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtokenizers/punkt/PY3/english.pickle\u001B[0m\n\n  Searched in:\n    - '/home/jbrunner/nltk_data'\n    - '/home/jbrunner/git-repos/kaggle/venv/nltk_data'\n    - '/home/jbrunner/git-repos/kaggle/venv/share/nltk_data'\n    - '/home/jbrunner/git-repos/kaggle/venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mLookupError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;32m~/git-repos/kaggle/venv/lib/python3.8/site-packages/pandas/core/series.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self, func, convert_dtype, args, **kwds)\u001B[0m\n\u001B[1;32m   4136\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4137\u001B[0m                 \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobject\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4138\u001B[0;31m                 \u001B[0mmapped\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_infer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconvert\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconvert_dtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   4139\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4140\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmapped\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmapped\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSeries\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/lib.pyx\u001B[0m in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/git-repos/kaggle/venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001B[0m in \u001B[0;36mword_tokenize\u001B[0;34m(text, language, preserve_line)\u001B[0m\n\u001B[1;32m    128\u001B[0m     \u001B[0;34m:\u001B[0m\u001B[0mtype\u001B[0m \u001B[0mpreserve_line\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbool\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m     \"\"\"\n\u001B[0;32m--> 130\u001B[0;31m     \u001B[0msentences\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mpreserve_line\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0msent_tokenize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlanguage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    131\u001B[0m     return [\n\u001B[1;32m    132\u001B[0m         \u001B[0mtoken\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0msent\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msentences\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mtoken\u001B[0m \u001B[0;32min\u001B[0m \u001B[0m_treebank_word_tokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/git-repos/kaggle/venv/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001B[0m in \u001B[0;36msent_tokenize\u001B[0;34m(text, language)\u001B[0m\n\u001B[1;32m    105\u001B[0m     \u001B[0;34m:\u001B[0m\u001B[0mparam\u001B[0m \u001B[0mlanguage\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mPunkt\u001B[0m \u001B[0mcorpus\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m     \"\"\"\n\u001B[0;32m--> 107\u001B[0;31m     \u001B[0mtokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"tokenizers/punkt/{0}.pickle\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlanguage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    108\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/git-repos/kaggle/venv/lib/python3.8/site-packages/nltk/data.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001B[0m\n\u001B[1;32m    748\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    749\u001B[0m     \u001B[0;31m# Load the resource.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 750\u001B[0;31m     \u001B[0mopened_resource\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresource_url\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    751\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    752\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mformat\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"raw\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/git-repos/kaggle/venv/lib/python3.8/site-packages/nltk/data.py\u001B[0m in \u001B[0;36m_open\u001B[0;34m(resource_url)\u001B[0m\n\u001B[1;32m    873\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    874\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mprotocol\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"nltk\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 875\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpath\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    876\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"file\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    877\u001B[0m         \u001B[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/git-repos/kaggle/venv/lib/python3.8/site-packages/nltk/data.py\u001B[0m in \u001B[0;36mfind\u001B[0;34m(resource_name, paths)\u001B[0m\n\u001B[1;32m    581\u001B[0m     \u001B[0msep\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"*\"\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;36m70\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    582\u001B[0m     \u001B[0mresource_not_found\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0msep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmsg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 583\u001B[0;31m     \u001B[0;32mraise\u001B[0m \u001B[0mLookupError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresource_not_found\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    584\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mLookupError\u001B[0m: \n**********************************************************************\n  Resource \u001B[93mpunkt\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtokenizers/punkt/PY3/english.pickle\u001B[0m\n\n  Searched in:\n    - '/home/jbrunner/nltk_data'\n    - '/home/jbrunner/git-repos/kaggle/venv/nltk_data'\n    - '/home/jbrunner/git-repos/kaggle/venv/share/nltk_data'\n    - '/home/jbrunner/git-repos/kaggle/venv/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['tokenized'] = train_df['text_clean'].apply(nltk.tokenize.word_tokenize)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Remove stopwords (eg. About, Above, Across, After, ..\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tokenized'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m~/git-repos/kaggle/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3079\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3080\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3081\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'tokenized'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;32m~/git-repos/kaggle/venv/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3022\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3023\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3024\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3025\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3026\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/git-repos/kaggle/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3080\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3081\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3082\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3083\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3084\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtolerance\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'tokenized'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['stopwords_removed'] = train_df['tokenized'].apply(lambda x: [word for word in x if word not in nltk.corpus.stop])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try to break words down to their root (ie. stemming)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'stopwords_removed'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m~/git-repos/kaggle/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3079\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3080\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3081\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'stopwords_removed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;32m~/git-repos/kaggle/venv/lib/python3.8/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3022\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3023\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3024\u001B[0;31m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3025\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3026\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/git-repos/kaggle/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36mget_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3080\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3081\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3082\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3083\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3084\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtolerance\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'stopwords_removed'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['stemmer'] = train_df['stopwords_removed'].apply(lambda x: stemmer(x))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Look at the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "          keyword                     location  \\\nid                                               \n9943      trouble                          NaN   \n175    aftershock                          NaN   \n8203         riot                          NaN   \n156    aftershock                           US   \n1032     bleeding                          NaN   \n2144  catastrophe                          NaN   \n6758    lightning  Rapid City, Black Hills, SD   \n8490     screamed              with Doflamingo   \n8522    screaming                 Jariana Town   \n8654     sinkhole                           NY   \n\n                                                   text  target  \\\nid                                                                \n9943  Love how I don't get in any trouble for having...       0   \n175   That moment when you get on a scary roller coa...       0   \n8203  To All The Meat-Loving Feminists Of The World ...       0   \n156   320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/vA...       0   \n1032  you could slit my throat and I'd apologize for...       0   \n2144  #nar #phuket Ultimate #preparedness library: h...       1   \n6758  NWS says thunderstorms with deadly lightning w...       1   \n8490  //kinda screamed &gt;_&lt; https://t.co/MSUY4q...       0   \n8522  @justinbieber @ArianaGrande Can you hear me sc...       0   \n8654  Gaping sinkhole opens up in Brooklyn New York ...       1   \n\n                                             text_clean  \nid                                                       \n9943  love how i do not get in any trouble for havin...  \n175   that moment when you get on a scary roller coa...  \n8203  to all the meatloving feminists of the world r...  \n156   320 ir icemoon aftershock    djicemoon  dubste...  \n1032  you could slit my throat and I would apologize...  \n2144  nar phuket ultimate preparedness library  prep...  \n6758  nws says thunderstorms with deadly lightning w...  \n8490                                 kind of screamed    \n8522  justinbieber arianagrande can you hear me scre...  \n8654     gaping sinkhole opens up in brooklyn new york   ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>text_clean</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9943</th>\n      <td>trouble</td>\n      <td>NaN</td>\n      <td>Love how I don't get in any trouble for having...</td>\n      <td>0</td>\n      <td>love how i do not get in any trouble for havin...</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>aftershock</td>\n      <td>NaN</td>\n      <td>That moment when you get on a scary roller coa...</td>\n      <td>0</td>\n      <td>that moment when you get on a scary roller coa...</td>\n    </tr>\n    <tr>\n      <th>8203</th>\n      <td>riot</td>\n      <td>NaN</td>\n      <td>To All The Meat-Loving Feminists Of The World ...</td>\n      <td>0</td>\n      <td>to all the meatloving feminists of the world r...</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>aftershock</td>\n      <td>US</td>\n      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/vA...</td>\n      <td>0</td>\n      <td>320 ir icemoon aftershock    djicemoon  dubste...</td>\n    </tr>\n    <tr>\n      <th>1032</th>\n      <td>bleeding</td>\n      <td>NaN</td>\n      <td>you could slit my throat and I'd apologize for...</td>\n      <td>0</td>\n      <td>you could slit my throat and I would apologize...</td>\n    </tr>\n    <tr>\n      <th>2144</th>\n      <td>catastrophe</td>\n      <td>NaN</td>\n      <td>#nar #phuket Ultimate #preparedness library: h...</td>\n      <td>1</td>\n      <td>nar phuket ultimate preparedness library  prep...</td>\n    </tr>\n    <tr>\n      <th>6758</th>\n      <td>lightning</td>\n      <td>Rapid City, Black Hills, SD</td>\n      <td>NWS says thunderstorms with deadly lightning w...</td>\n      <td>1</td>\n      <td>nws says thunderstorms with deadly lightning w...</td>\n    </tr>\n    <tr>\n      <th>8490</th>\n      <td>screamed</td>\n      <td>with Doflamingo</td>\n      <td>//kinda screamed &amp;gt;_&amp;lt; https://t.co/MSUY4q...</td>\n      <td>0</td>\n      <td>kind of screamed</td>\n    </tr>\n    <tr>\n      <th>8522</th>\n      <td>screaming</td>\n      <td>Jariana Town</td>\n      <td>@justinbieber @ArianaGrande Can you hear me sc...</td>\n      <td>0</td>\n      <td>justinbieber arianagrande can you hear me scre...</td>\n    </tr>\n    <tr>\n      <th>8654</th>\n      <td>sinkhole</td>\n      <td>NY</td>\n      <td>Gaping sinkhole opens up in Brooklyn New York ...</td>\n      <td>1</td>\n      <td>gaping sinkhole opens up in brooklyn new york</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}